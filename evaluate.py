import argparseimport torchimport torch.nn as nnimport torch.nn.functional as Fimport torch.optim as optimimport torchvisionimport torchvision.transforms as transformsimport torchvision.datasets as datasetsfrom torch.utils.data import DataLoader, Datasetfrom PIL import Imageimport osimport randomimport numpy as npfrom torch.autograd import Variable# class_to_idx = dict({'rests': 0, 'shelf': 1, 'shop': 2})class_to_idx = dict({'0': 0, '180': 1, '270': 2, '90': 3})idx_to_class = dict(zip(class_to_idx.values(), class_to_idx.keys()))img_transforms = transforms.Compose([        # transforms.CenterCrop((224, 224)),        transforms.Resize((224, 224)),        transforms.ToTensor(),        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))    ])class myDataset(Dataset):    def __init__(self, image_path):        self.filenames = list()        for r, dirs, files in os.walk(image_path):            self.filenames.append(os.path.join(r, files))    # override __getitem__(), __len__()    def __getitem__(self, index):        path = self.filenames[index]        img = Image.open(path.strip())        img = torch.Tensor(img)        return img    def __len__(self):        return len(self.filenames)def parse_args():    parser = argparse.ArgumentParser(description='Evaluate classification')    parser.add_argument('image', type=str, help='image path')    parser.add_argument('model', type=str, help='model path')    parser.add_argument('--batch', type=bool, default=False, help='Evaluate batch data')    parser.add_argument('--batch_size', type=int, default=64, help='Batch size')    parser.add_argument(        '--resume_from', help='the checkpoint file to resume from')    parser.add_argument(        '--validate',        action='store_true',        help='whether to evaluate the checkpoint during training')    parser.add_argument(        '--gpus',        type=int,        default=1,        help='number of gpus to use '        '(only applicable to non-distributed training)')    parser.add_argument('--seed', type=int, default=None, help='random seed')    parser.add_argument(        '--launcher',        choices=['none', 'pytorch', 'slurm', 'mpi'],        default='none',        help='job launcher')    parser.add_argument('--local_rank', type=int, default=0)    args = parser.parse_args()    return argsdef single_image_evaluate(args, device, model):    model.eval()    img = Image.open(args.image)    if img is None:        print("Image %s not found.\n" % args.image)        return    img = img.convert("RGB")    image_tensor = img_transforms(img).float()    image_tensor = image_tensor.unsqueeze_(0)    image_tensor.to(device)    input = Variable(image_tensor).to(device)    with torch.no_grad():        output = model(input)    softmax = F.softmax(output).cpu().numpy()[0]    print(softmax)    result = output.data.cpu().numpy().argmax()    # if result == 0 and softmax[2] > 0.1:    #     result = 2    print(idx_to_class[result])def main():    args = parse_args()    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")    import torchvision.models as models    model = models.resnet101(pretrained=False).to(device)    fc_features = model.fc.in_features    model.fc = nn.Linear(in_features=fc_features, out_features=4).to(device)    model.load_state_dict(torch.load(args.model))    if not args.batch:        single_image_evaluate(args, device, model)    else:        dataset = myDataset        dataloader = DataLoader(dataset(image_path=args.image), batch_size=args.batch_size)if __name__ == "__main__":    main()